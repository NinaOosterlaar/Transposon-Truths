Task 1: Training ZINBVAE
Device: cuda
Loading training data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_train_data.npy
Loading test data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_test_data.npy
Number of training samples: 14824
============================================================
TRAINING ZINB VARIATIONAL AUTOENCODER (ZINBVAE)
============================================================
Epoch [1/100], Total Loss: 1.6611, Recon: 1.6518, KL: 0.0093
Epoch [2/100], Total Loss: 1.6004, Recon: 1.5979, KL: 0.0024
Epoch [3/100], Total Loss: 1.5869, Recon: 1.5830, KL: 0.0039
Epoch [4/100], Total Loss: 1.5839, Recon: 1.5794, KL: 0.0045
Epoch [5/100], Total Loss: 1.5766, Recon: 1.5725, KL: 0.0041
Epoch [6/100], Total Loss: 1.5714, Recon: 1.5676, KL: 0.0038
Epoch [7/100], Total Loss: 1.5683, Recon: 1.5645, KL: 0.0038
Epoch [8/100], Total Loss: 1.5658, Recon: 1.5620, KL: 0.0037
Epoch [9/100], Total Loss: 1.5652, Recon: 1.5616, KL: 0.0036
Epoch [10/100], Total Loss: 1.5634, Recon: 1.5601, KL: 0.0033
Epoch [11/100], Total Loss: 1.5617, Recon: 1.5587, KL: 0.0031
Epoch [12/100], Total Loss: 1.5627, Recon: 1.5597, KL: 0.0030
Epoch [13/100], Total Loss: 1.5670, Recon: 1.5639, KL: 0.0031
Epoch [14/100], Total Loss: 1.5635, Recon: 1.5606, KL: 0.0029
Epoch [15/100], Total Loss: 1.5587, Recon: 1.5557, KL: 0.0030
Epoch [16/100], Total Loss: 1.5524, Recon: 1.5484, KL: 0.0040
Epoch [17/100], Total Loss: 1.5517, Recon: 1.5476, KL: 0.0040
Epoch [18/100], Total Loss: 1.5527, Recon: 1.5486, KL: 0.0041
Epoch [19/100], Total Loss: 1.5495, Recon: 1.5455, KL: 0.0040
Epoch [20/100], Total Loss: 1.5484, Recon: 1.5444, KL: 0.0040
Epoch [21/100], Total Loss: 1.5484, Recon: 1.5446, KL: 0.0038
Epoch [22/100], Total Loss: 1.5466, Recon: 1.5429, KL: 0.0037
Epoch [23/100], Total Loss: 1.5462, Recon: 1.5425, KL: 0.0037
Epoch [24/100], Total Loss: 1.5460, Recon: 1.5423, KL: 0.0036
Epoch [25/100], Total Loss: 1.5451, Recon: 1.5415, KL: 0.0036
Epoch [26/100], Total Loss: 1.5449, Recon: 1.5413, KL: 0.0036
Epoch [27/100], Total Loss: 1.5446, Recon: 1.5410, KL: 0.0036
Epoch [28/100], Total Loss: 1.5437, Recon: 1.5401, KL: 0.0036
Epoch [29/100], Total Loss: 1.5505, Recon: 1.5467, KL: 0.0038
Epoch [30/100], Total Loss: 1.5424, Recon: 1.5382, KL: 0.0042
Epoch [31/100], Total Loss: 1.5398, Recon: 1.5351, KL: 0.0047
Epoch [32/100], Total Loss: 1.5372, Recon: 1.5324, KL: 0.0048
Epoch [33/100], Total Loss: 1.5368, Recon: 1.5319, KL: 0.0048
Epoch [34/100], Total Loss: 1.5369, Recon: 1.5320, KL: 0.0050
Epoch [35/100], Total Loss: 1.5353, Recon: 1.5303, KL: 0.0049
Epoch [36/100], Total Loss: 1.5430, Recon: 1.5381, KL: 0.0049
Epoch [37/100], Total Loss: 1.5340, Recon: 1.5292, KL: 0.0047
Epoch [38/100], Total Loss: 1.5332, Recon: 1.5285, KL: 0.0047
Epoch [39/100], Total Loss: 1.5318, Recon: 1.5271, KL: 0.0047
Epoch [40/100], Total Loss: 1.5316, Recon: 1.5269, KL: 0.0048
Epoch [41/100], Total Loss: 1.5305, Recon: 1.5257, KL: 0.0047
Epoch [42/100], Total Loss: 1.5300, Recon: 1.5252, KL: 0.0048
Epoch [43/100], Total Loss: 1.5305, Recon: 1.5256, KL: 0.0049
Epoch [44/100], Total Loss: 1.5297, Recon: 1.5248, KL: 0.0049
Epoch [45/100], Total Loss: 1.5289, Recon: 1.5239, KL: 0.0050
Epoch [46/100], Total Loss: 1.5288, Recon: 1.5238, KL: 0.0050
Epoch [47/100], Total Loss: 1.5275, Recon: 1.5225, KL: 0.0050
Epoch [48/100], Total Loss: 1.5269, Recon: 1.5216, KL: 0.0053
Epoch [49/100], Total Loss: 1.5253, Recon: 1.5196, KL: 0.0057
Epoch [50/100], Total Loss: 1.5231, Recon: 1.5172, KL: 0.0059
Epoch [51/100], Total Loss: 1.5219, Recon: 1.5158, KL: 0.0061
Epoch [52/100], Total Loss: 1.5201, Recon: 1.5140, KL: 0.0061
Epoch [53/100], Total Loss: 1.5185, Recon: 1.5125, KL: 0.0061
Epoch [54/100], Total Loss: 1.5248, Recon: 1.5188, KL: 0.0060
Epoch [55/100], Total Loss: 1.5191, Recon: 1.5131, KL: 0.0060
Epoch [56/100], Total Loss: 1.5156, Recon: 1.5095, KL: 0.0061
Epoch [57/100], Total Loss: 1.5164, Recon: 1.5103, KL: 0.0061
Epoch [58/100], Total Loss: 1.5143, Recon: 1.5081, KL: 0.0061
Epoch [59/100], Total Loss: 1.5141, Recon: 1.5080, KL: 0.0061
Epoch [60/100], Total Loss: 1.5141, Recon: 1.5079, KL: 0.0062
Epoch [61/100], Total Loss: 1.5119, Recon: 1.5056, KL: 0.0062
Epoch [62/100], Total Loss: 1.5110, Recon: 1.5048, KL: 0.0062
Epoch [63/100], Total Loss: 1.5105, Recon: 1.5042, KL: 0.0062
Epoch [64/100], Total Loss: 1.5138, Recon: 1.5075, KL: 0.0064
Epoch [65/100], Total Loss: 1.5094, Recon: 1.5031, KL: 0.0064
Epoch [66/100], Total Loss: 1.5081, Recon: 1.5017, KL: 0.0064
Epoch [67/100], Total Loss: 1.5090, Recon: 1.5026, KL: 0.0064
Epoch [68/100], Total Loss: 1.5124, Recon: 1.5059, KL: 0.0064
Epoch [69/100], Total Loss: 1.5070, Recon: 1.5006, KL: 0.0065
Epoch [70/100], Total Loss: 1.5056, Recon: 1.4991, KL: 0.0065
Epoch [71/100], Total Loss: 1.5043, Recon: 1.4978, KL: 0.0065
Epoch [72/100], Total Loss: 1.5039, Recon: 1.4974, KL: 0.0065
Epoch [73/100], Total Loss: 1.5036, Recon: 1.4969, KL: 0.0066
Epoch [74/100], Total Loss: 1.5024, Recon: 1.4958, KL: 0.0066
Epoch [75/100], Total Loss: 1.5024, Recon: 1.4958, KL: 0.0066
Epoch [76/100], Total Loss: 1.5022, Recon: 1.4955, KL: 0.0067
Epoch [77/100], Total Loss: 1.5015, Recon: 1.4948, KL: 0.0067
Epoch [78/100], Total Loss: 1.5003, Recon: 1.4936, KL: 0.0067
Epoch [79/100], Total Loss: 1.4989, Recon: 1.4922, KL: 0.0067
Epoch [80/100], Total Loss: 1.5005, Recon: 1.4938, KL: 0.0068
Epoch [81/100], Total Loss: 1.4994, Recon: 1.4926, KL: 0.0068
Epoch [82/100], Total Loss: 1.4977, Recon: 1.4909, KL: 0.0068
Epoch [83/100], Total Loss: 1.4968, Recon: 1.4900, KL: 0.0068
Epoch [84/100], Total Loss: 1.4963, Recon: 1.4894, KL: 0.0068
Epoch [85/100], Total Loss: 1.4966, Recon: 1.4897, KL: 0.0069
Epoch [86/100], Total Loss: 1.4960, Recon: 1.4891, KL: 0.0069
Epoch [87/100], Total Loss: 1.4953, Recon: 1.4884, KL: 0.0069
Epoch [88/100], Total Loss: 1.4943, Recon: 1.4873, KL: 0.0070
Epoch [89/100], Total Loss: 1.4937, Recon: 1.4867, KL: 0.0070
Epoch [90/100], Total Loss: 1.4940, Recon: 1.4870, KL: 0.0070
Epoch [91/100], Total Loss: 1.4930, Recon: 1.4860, KL: 0.0070
Epoch [92/100], Total Loss: 1.4928, Recon: 1.4857, KL: 0.0071
Epoch [93/100], Total Loss: 1.4918, Recon: 1.4848, KL: 0.0070
Epoch [94/100], Total Loss: 1.4911, Recon: 1.4840, KL: 0.0071
Epoch [95/100], Total Loss: 1.4905, Recon: 1.4834, KL: 0.0071
Epoch [96/100], Total Loss: 1.4925, Recon: 1.4854, KL: 0.0071
Epoch [97/100], Total Loss: 1.4908, Recon: 1.4837, KL: 0.0071
Epoch [98/100], Total Loss: 1.4898, Recon: 1.4826, KL: 0.0072
Epoch [99/100], Total Loss: 1.4882, Recon: 1.4810, KL: 0.0072
Epoch [100/100], Total Loss: 1.4886, Recon: 1.4814, KL: 0.0072
Training loss plots saved to /workspace/AE/results/training/trial_new/
Training losses saved to /workspace/AE/results/training/trial_new/trial_new_ZINBVAE_20260115_142003_conv_training_losses.json

==================================================
EVALUATING ON TRAINING DATA
==================================================

==================================================
TEST RESULTS
==================================================
Test Loss (ZINB NLL): 1.486464
Mean Absolute Error (MAE): 2.207913
R² Score: -60.134537
Reconstruction Loss: 1.479298
KL Divergence: 0.007166
==================================================

Using raw counts for evaluation metrics.
29648000 13164927 16483073
ZINB metrics saved to /workspace/AE/results/training/trial_new/trial_new_ZINBVAE_20260115_142006_conv_test_metrics.json
ZINB-specific plots saved to /workspace/AE/results/training/trial_new/

==================================================
TEST RESULTS
==================================================
Test Loss (ZINB NLL): 1.684081
Mean Absolute Error (MAE): 2.383439
R² Score: -45.733158
Reconstruction Loss: 1.677267
KL Divergence: 0.006813
==================================================

Using raw counts for evaluation metrics.
3920000 1662825 2257175
ZINB metrics saved to /workspace/AE/results/testing/trial_new/trial_new_ZINBVAE_20260115_143334_conv_test_metrics.json
ZINB-specific plots saved to /workspace/AE/results/testing/trial_new/
