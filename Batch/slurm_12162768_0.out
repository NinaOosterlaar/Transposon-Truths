Task 0: Training ZINBAE
Device: cuda
Loading training data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_train_data.npy
Applied denoising with 30.0% masking
Loading test data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_test_data.npy
Applied denoising with 30.0% masking
Number of training samples: 14824
============================================================
TRAINING ZINB AUTOENCODER (ZINBAE)
============================================================
Epoch [1/100], Total Loss: 5.2755, NLL: 2.6347, Masked: 2.6409
Epoch [2/100], Total Loss: 4.4866, NLL: 2.1820, Masked: 2.3046
Epoch [3/100], Total Loss: 4.4086, NLL: 2.1331, Masked: 2.2755
Epoch [4/100], Total Loss: 4.3178, NLL: 2.0718, Masked: 2.2460
Epoch [5/100], Total Loss: 4.2587, NLL: 2.0422, Masked: 2.2166
Epoch [6/100], Total Loss: 4.2671, NLL: 2.0484, Masked: 2.2186
Epoch [7/100], Total Loss: 4.2090, NLL: 2.0139, Masked: 2.1951
Epoch [8/100], Total Loss: 80.4938, NLL: 2.0508, Masked: 78.4431
Epoch [9/100], Total Loss: 4.1922, NLL: 2.0024, Masked: 2.1898
Epoch [10/100], Total Loss: 4.2284, NLL: 2.0226, Masked: 2.2058
Epoch [11/100], Total Loss: 4.2003, NLL: 2.0142, Masked: 2.1861
Epoch [12/100], Total Loss: 4.1740, NLL: 1.9940, Masked: 2.1800
Epoch [13/100], Total Loss: 4.1029, NLL: 1.9551, Masked: 2.1479
Epoch [14/100], Total Loss: 4.0963, NLL: 1.9545, Masked: 2.1417
Epoch [15/100], Total Loss: 4.1274, NLL: 1.9699, Masked: 2.1575
Epoch [16/100], Total Loss: 4.1150, NLL: 1.9616, Masked: 2.1534
Epoch [17/100], Total Loss: 4.1276, NLL: 1.9688, Masked: 2.1588
Epoch [18/100], Total Loss: 4.0979, NLL: 1.9587, Masked: 2.1391
Epoch [19/100], Total Loss: 4.1063, NLL: 1.9531, Masked: 2.1532
Epoch [20/100], Total Loss: 4.0642, NLL: 1.9406, Masked: 2.1236
Epoch [21/100], Total Loss: 4.0467, NLL: 1.9343, Masked: 2.1124
Epoch [22/100], Total Loss: 4.0549, NLL: 1.9394, Masked: 2.1156
Epoch [23/100], Total Loss: 4.0500, NLL: 1.9369, Masked: 2.1132
Epoch [24/100], Total Loss: 4.0358, NLL: 1.9321, Masked: 2.1037
Epoch [25/100], Total Loss: 4.0297, NLL: 1.9316, Masked: 2.0982
Epoch [26/100], Total Loss: 4.0168, NLL: 1.9270, Masked: 2.0899
Epoch [27/100], Total Loss: 4.0176, NLL: 1.9221, Masked: 2.0955
Epoch [28/100], Total Loss: 4.0003, NLL: 1.9181, Masked: 2.0821
Epoch [29/100], Total Loss: 3.9931, NLL: 1.9135, Masked: 2.0795
Epoch [30/100], Total Loss: 3.9826, NLL: 1.9103, Masked: 2.0722
Epoch [31/100], Total Loss: 3.9725, NLL: 1.9085, Masked: 2.0640
Epoch [32/100], Total Loss: 3.9637, NLL: 1.9043, Masked: 2.0594
Epoch [33/100], Total Loss: 3.9492, NLL: 1.9012, Masked: 2.0480
Epoch [34/100], Total Loss: 3.9499, NLL: 1.9008, Masked: 2.0491
Epoch [35/100], Total Loss: 3.9481, NLL: 1.9001, Masked: 2.0480
Epoch [36/100], Total Loss: 3.9311, NLL: 1.8972, Masked: 2.0339
Epoch [37/100], Total Loss: 3.9279, NLL: 1.8973, Masked: 2.0306
Epoch [38/100], Total Loss: 3.9194, NLL: 1.8944, Masked: 2.0250
Epoch [39/100], Total Loss: 3.9095, NLL: 1.8915, Masked: 2.0180
Epoch [40/100], Total Loss: 3.9107, NLL: 1.8900, Masked: 2.0207
Epoch [41/100], Total Loss: 3.8923, NLL: 1.8868, Masked: 2.0056
Epoch [42/100], Total Loss: 3.8876, NLL: 1.8840, Masked: 2.0036
Epoch [43/100], Total Loss: 3.8819, NLL: 1.8825, Masked: 1.9993
Epoch [44/100], Total Loss: 3.8702, NLL: 1.8805, Masked: 1.9896
Epoch [45/100], Total Loss: 3.8633, NLL: 1.8785, Masked: 1.9848
Epoch [46/100], Total Loss: 3.8642, NLL: 1.8786, Masked: 1.9856
Epoch [47/100], Total Loss: 3.8544, NLL: 1.8761, Masked: 1.9783
Epoch [48/100], Total Loss: 5.0453, NLL: 1.8903, Masked: 3.1550
Epoch [49/100], Total Loss: 3.8410, NLL: 1.8724, Masked: 1.9686
Epoch [50/100], Total Loss: 3.8410, NLL: 1.8717, Masked: 1.9693
Epoch [51/100], Total Loss: 3.8350, NLL: 1.8713, Masked: 1.9637
Epoch [52/100], Total Loss: 3.8310, NLL: 1.8693, Masked: 1.9617
Epoch [53/100], Total Loss: 3.8157, NLL: 1.8669, Masked: 1.9488
Epoch [54/100], Total Loss: 3.8140, NLL: 1.8661, Masked: 1.9480
Epoch [55/100], Total Loss: 3.8099, NLL: 1.8652, Masked: 1.9447
Epoch [56/100], Total Loss: 3.8034, NLL: 1.8631, Masked: 1.9403
Epoch [57/100], Total Loss: 3.7989, NLL: 1.8620, Masked: 1.9369
Epoch [58/100], Total Loss: 3.7893, NLL: 1.8607, Masked: 1.9286
Epoch [59/100], Total Loss: 3.7854, NLL: 1.8593, Masked: 1.9261
Epoch [60/100], Total Loss: 3.7813, NLL: 1.8584, Masked: 1.9229
Epoch [61/100], Total Loss: 3.7743, NLL: 1.8572, Masked: 1.9171
Epoch [62/100], Total Loss: 3.7710, NLL: 1.8568, Masked: 1.9142
Epoch [63/100], Total Loss: 3.7673, NLL: 1.8555, Masked: 1.9117
Epoch [64/100], Total Loss: 3.7640, NLL: 1.8554, Masked: 1.9086
Epoch [65/100], Total Loss: 3.7579, NLL: 1.8540, Masked: 1.9039
Epoch [66/100], Total Loss: 3.7516, NLL: 1.8528, Masked: 1.8988
Epoch [67/100], Total Loss: 3.7479, NLL: 1.8517, Masked: 1.8962
Epoch [68/100], Total Loss: 3.7444, NLL: 1.8516, Masked: 1.8927
Epoch [69/100], Total Loss: 3.7445, NLL: 1.8514, Masked: 1.8931
Epoch [70/100], Total Loss: 3.7406, NLL: 1.8503, Masked: 1.8903
Epoch [71/100], Total Loss: 3.7365, NLL: 1.8501, Masked: 1.8865
Epoch [72/100], Total Loss: 3.7304, NLL: 1.8485, Masked: 1.8819
Epoch [73/100], Total Loss: 3.7286, NLL: 1.8478, Masked: 1.8808
Epoch [74/100], Total Loss: 3.7261, NLL: 1.8479, Masked: 1.8782
Epoch [75/100], Total Loss: 3.7249, NLL: 1.8467, Masked: 1.8782
Epoch [76/100], Total Loss: 3.7206, NLL: 1.8466, Masked: 1.8740
Epoch [77/100], Total Loss: 3.7145, NLL: 1.8451, Masked: 1.8694
Epoch [78/100], Total Loss: 3.7121, NLL: 1.8451, Masked: 1.8670
Epoch [79/100], Total Loss: 3.7067, NLL: 1.8438, Masked: 1.8629
Epoch [80/100], Total Loss: 3.7072, NLL: 1.8438, Masked: 1.8634
Epoch [81/100], Total Loss: 3.7053, NLL: 1.8434, Masked: 1.8619
Epoch [82/100], Total Loss: 3.7019, NLL: 1.8430, Masked: 1.8589
Epoch [83/100], Total Loss: 3.7019, NLL: 1.8429, Masked: 1.8591
Epoch [84/100], Total Loss: 3.6945, NLL: 1.8415, Masked: 1.8531
Epoch [85/100], Total Loss: 3.6963, NLL: 1.8411, Masked: 1.8552
Epoch [86/100], Total Loss: 3.6941, NLL: 1.8413, Masked: 1.8527
Epoch [87/100], Total Loss: 3.6902, NLL: 1.8405, Masked: 1.8497
Epoch [88/100], Total Loss: 3.6856, NLL: 1.8389, Masked: 1.8466
Epoch [89/100], Total Loss: 3.6840, NLL: 1.8392, Masked: 1.8447
Epoch [90/100], Total Loss: 3.6812, NLL: 1.8384, Masked: 1.8428
Epoch [91/100], Total Loss: 3.6788, NLL: 1.8379, Masked: 1.8409
Epoch [92/100], Total Loss: 3.6757, NLL: 1.8375, Masked: 1.8382
Epoch [93/100], Total Loss: 3.6771, NLL: 1.8376, Masked: 1.8396
Epoch [94/100], Total Loss: 3.6722, NLL: 1.8368, Masked: 1.8354
Epoch [95/100], Total Loss: 3.6687, NLL: 1.8361, Masked: 1.8326
Epoch [96/100], Total Loss: 3.6722, NLL: 1.8366, Masked: 1.8357
Epoch [97/100], Total Loss: 3.6646, NLL: 1.8352, Masked: 1.8295
Epoch [98/100], Total Loss: 3.6617, NLL: 1.8351, Masked: 1.8266
Epoch [99/100], Total Loss: 3.6604, NLL: 1.8347, Masked: 1.8257
Epoch [100/100], Total Loss: 3.6597, NLL: 1.8341, Masked: 1.8256
Training loss plot saved to /workspace/AE/results/training/this_is_pi_loss/this_is_pi_loss_ZINBAE_20260119_132556_conv_training_losses.png
Training losses saved to /workspace/AE/results/training/this_is_pi_loss/this_is_pi_loss_ZINBAE_20260119_132556_conv_training_losses.json

==================================================
EVALUATING ON TRAINING DATA
==================================================
