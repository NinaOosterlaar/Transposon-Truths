Task 1: Training ZINBVAE
Device: cuda
Loading training data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_train_data.npy
Loading test data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_test_data.npy
Number of training samples: 14824
============================================================
TRAINING ZINB VARIATIONAL AUTOENCODER (ZINBVAE)
============================================================
Epoch [1/100], Total Loss: 2.1008, Recon: 2.0688, KL: 0.0319
Epoch [2/100], Total Loss: 1.8935, Recon: 1.8860, KL: 0.0074
Epoch [3/100], Total Loss: 1.8844, Recon: 1.8772, KL: 0.0072
Epoch [4/100], Total Loss: 1.8817, Recon: 1.8750, KL: 0.0068
Epoch [5/100], Total Loss: 1.8723, Recon: 1.8666, KL: 0.0057
Epoch [6/100], Total Loss: 1.8691, Recon: 1.8639, KL: 0.0053
Epoch [7/100], Total Loss: 1.8705, Recon: 1.8658, KL: 0.0047
Epoch [8/100], Total Loss: 1.8648, Recon: 1.8605, KL: 0.0043
Epoch [9/100], Total Loss: 1.8655, Recon: 1.8614, KL: 0.0041
Epoch [10/100], Total Loss: 1.8630, Recon: 1.8591, KL: 0.0040
Epoch [11/100], Total Loss: 1.8628, Recon: 1.8590, KL: 0.0037
Epoch [12/100], Total Loss: 1.8610, Recon: 1.8574, KL: 0.0035
Epoch [13/100], Total Loss: 1.8618, Recon: 1.8583, KL: 0.0035
Epoch [14/100], Total Loss: 1.8601, Recon: 1.8567, KL: 0.0034
Epoch [15/100], Total Loss: 1.8612, Recon: 1.8578, KL: 0.0034
Epoch [16/100], Total Loss: 1.8597, Recon: 1.8563, KL: 0.0033
Epoch [17/100], Total Loss: 1.8571, Recon: 1.8539, KL: 0.0032
Epoch [18/100], Total Loss: 1.8603, Recon: 1.8569, KL: 0.0034
Epoch [19/100], Total Loss: 1.8581, Recon: 1.8548, KL: 0.0033
Epoch [20/100], Total Loss: 1.8563, Recon: 1.8532, KL: 0.0032
Epoch [21/100], Total Loss: 1.8606, Recon: 1.8574, KL: 0.0032
Epoch [22/100], Total Loss: 1.8562, Recon: 1.8530, KL: 0.0031
Epoch [23/100], Total Loss: 1.8559, Recon: 1.8528, KL: 0.0031
Epoch [24/100], Total Loss: 1.8552, Recon: 1.8521, KL: 0.0031
Epoch [25/100], Total Loss: 1.8561, Recon: 1.8529, KL: 0.0032
Epoch [26/100], Total Loss: 1.8534, Recon: 1.8493, KL: 0.0042
Epoch [27/100], Total Loss: 1.8488, Recon: 1.8443, KL: 0.0044
Epoch [28/100], Total Loss: 1.8463, Recon: 1.8419, KL: 0.0045
Epoch [29/100], Total Loss: 1.8453, Recon: 1.8407, KL: 0.0045
Epoch [30/100], Total Loss: 1.8441, Recon: 1.8396, KL: 0.0044
Epoch [31/100], Total Loss: 1.8418, Recon: 1.8376, KL: 0.0042
Epoch [32/100], Total Loss: 1.8419, Recon: 1.8378, KL: 0.0042
Epoch [33/100], Total Loss: 1.8421, Recon: 1.8379, KL: 0.0042
Epoch [34/100], Total Loss: 1.8418, Recon: 1.8375, KL: 0.0043
Epoch [35/100], Total Loss: 1.8403, Recon: 1.8359, KL: 0.0044
Epoch [36/100], Total Loss: 1.8374, Recon: 1.8328, KL: 0.0046
Epoch [37/100], Total Loss: 1.8368, Recon: 1.8319, KL: 0.0050
Epoch [38/100], Total Loss: 1.8342, Recon: 1.8289, KL: 0.0053
Epoch [39/100], Total Loss: 1.8311, Recon: 1.8256, KL: 0.0055
Epoch [40/100], Total Loss: 1.8311, Recon: 1.8254, KL: 0.0058
Epoch [41/100], Total Loss: 1.8267, Recon: 1.8206, KL: 0.0062
Epoch [42/100], Total Loss: 1.8245, Recon: 1.8180, KL: 0.0065
Epoch [43/100], Total Loss: 1.8221, Recon: 1.8156, KL: 0.0065
Epoch [44/100], Total Loss: 1.8220, Recon: 1.8155, KL: 0.0065
Epoch [45/100], Total Loss: 1.8182, Recon: 1.8116, KL: 0.0066
Epoch [46/100], Total Loss: 1.8182, Recon: 1.8115, KL: 0.0067
Epoch [47/100], Total Loss: 1.8164, Recon: 1.8097, KL: 0.0067
Epoch [48/100], Total Loss: 1.8135, Recon: 1.8068, KL: 0.0067
Epoch [49/100], Total Loss: 1.8134, Recon: 1.8065, KL: 0.0069
Epoch [50/100], Total Loss: 1.8100, Recon: 1.8031, KL: 0.0069
Epoch [51/100], Total Loss: 1.8087, Recon: 1.8017, KL: 0.0071
Epoch [52/100], Total Loss: 1.8086, Recon: 1.8015, KL: 0.0071
Epoch [53/100], Total Loss: 1.8072, Recon: 1.8000, KL: 0.0072
Epoch [54/100], Total Loss: 1.8044, Recon: 1.7970, KL: 0.0073
Epoch [55/100], Total Loss: 1.8042, Recon: 1.7967, KL: 0.0075
Epoch [56/100], Total Loss: 1.8024, Recon: 1.7948, KL: 0.0077
Epoch [57/100], Total Loss: 1.8009, Recon: 1.7933, KL: 0.0076
Epoch [58/100], Total Loss: 1.7994, Recon: 1.7918, KL: 0.0076
Epoch [59/100], Total Loss: 1.7981, Recon: 1.7904, KL: 0.0077
Epoch [60/100], Total Loss: 1.8036, Recon: 1.7958, KL: 0.0078
Epoch [61/100], Total Loss: 1.7968, Recon: 1.7890, KL: 0.0078
Epoch [62/100], Total Loss: 1.7968, Recon: 1.7890, KL: 0.0078
Epoch [63/100], Total Loss: 1.7943, Recon: 1.7865, KL: 0.0078
Epoch [64/100], Total Loss: 1.7939, Recon: 1.7861, KL: 0.0078
Epoch [65/100], Total Loss: 1.7952, Recon: 1.7874, KL: 0.0078
Epoch [66/100], Total Loss: 1.7921, Recon: 1.7843, KL: 0.0078
Epoch [67/100], Total Loss: 1.7929, Recon: 1.7851, KL: 0.0078
Epoch [68/100], Total Loss: 1.7916, Recon: 1.7838, KL: 0.0079
Epoch [69/100], Total Loss: 1.7900, Recon: 1.7821, KL: 0.0079
Epoch [70/100], Total Loss: 1.7890, Recon: 1.7811, KL: 0.0079
Epoch [71/100], Total Loss: 1.7880, Recon: 1.7800, KL: 0.0080
Epoch [72/100], Total Loss: 1.7867, Recon: 1.7787, KL: 0.0079
Epoch [73/100], Total Loss: 1.7863, Recon: 1.7784, KL: 0.0079
Epoch [74/100], Total Loss: 1.7848, Recon: 1.7769, KL: 0.0080
Epoch [75/100], Total Loss: 1.7850, Recon: 1.7770, KL: 0.0080
Epoch [76/100], Total Loss: 1.7831, Recon: 1.7751, KL: 0.0080
Epoch [77/100], Total Loss: 1.7824, Recon: 1.7744, KL: 0.0081
Epoch [78/100], Total Loss: 1.7823, Recon: 1.7742, KL: 0.0081
Epoch [79/100], Total Loss: 1.7819, Recon: 1.7738, KL: 0.0081
Epoch [80/100], Total Loss: 1.7813, Recon: 1.7731, KL: 0.0082
Epoch [81/100], Total Loss: 1.7819, Recon: 1.7736, KL: 0.0083
Epoch [82/100], Total Loss: 1.7800, Recon: 1.7717, KL: 0.0083
Epoch [83/100], Total Loss: 1.7786, Recon: 1.7703, KL: 0.0083
Epoch [84/100], Total Loss: 1.7785, Recon: 1.7701, KL: 0.0083
Epoch [85/100], Total Loss: 1.7771, Recon: 1.7688, KL: 0.0083
Epoch [86/100], Total Loss: 1.7770, Recon: 1.7687, KL: 0.0084
Epoch [87/100], Total Loss: 1.7758, Recon: 1.7674, KL: 0.0084
Epoch [88/100], Total Loss: 1.7750, Recon: 1.7666, KL: 0.0084
Epoch [89/100], Total Loss: 1.7753, Recon: 1.7669, KL: 0.0085
Epoch [90/100], Total Loss: 1.7741, Recon: 1.7657, KL: 0.0085
Epoch [91/100], Total Loss: 1.7731, Recon: 1.7646, KL: 0.0085
Epoch [92/100], Total Loss: 1.7728, Recon: 1.7642, KL: 0.0086
Epoch [93/100], Total Loss: 1.7727, Recon: 1.7641, KL: 0.0086
Epoch [94/100], Total Loss: 1.7730, Recon: 1.7644, KL: 0.0086
Epoch [95/100], Total Loss: 1.7715, Recon: 1.7629, KL: 0.0086
Epoch [96/100], Total Loss: 1.7703, Recon: 1.7617, KL: 0.0087
Epoch [97/100], Total Loss: 1.7704, Recon: 1.7617, KL: 0.0087
Epoch [98/100], Total Loss: 1.7696, Recon: 1.7608, KL: 0.0087
Epoch [99/100], Total Loss: 1.7689, Recon: 1.7601, KL: 0.0087
Epoch [100/100], Total Loss: 1.7684, Recon: 1.7597, KL: 0.0087
Training loss plots saved to /workspace/AE/results/training/trial2/
Training losses saved to /workspace/AE/results/training/trial2/trial2_ZINBVAE_20260116_111735_conv_training_losses.json

==================================================
EVALUATING ON TRAINING DATA
==================================================
