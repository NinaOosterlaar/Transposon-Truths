Task 1: Training ZINBVAE
Device: cuda
Loading training data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_train_data.npy
Loading test data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_test_data.npy
Number of training samples: 14824
============================================================
TRAINING ZINB VARIATIONAL AUTOENCODER (ZINBVAE)
============================================================
Epoch [1/100], Total Loss: 1.6179, Recon: 1.6139, KL: 0.0040
Epoch [2/100], Total Loss: 1.5862, Recon: 1.5815, KL: 0.0047
Epoch [3/100], Total Loss: 1.5785, Recon: 1.5736, KL: 0.0049
Epoch [4/100], Total Loss: 1.5737, Recon: 1.5692, KL: 0.0044
Epoch [5/100], Total Loss: 1.5710, Recon: 1.5670, KL: 0.0041
Epoch [6/100], Total Loss: 1.5690, Recon: 1.5649, KL: 0.0041
Epoch [7/100], Total Loss: 1.5656, Recon: 1.5618, KL: 0.0038
Epoch [8/100], Total Loss: 1.5655, Recon: 1.5621, KL: 0.0034
Epoch [9/100], Total Loss: 1.5695, Recon: 1.5665, KL: 0.0030
Epoch [10/100], Total Loss: 1.5654, Recon: 1.5623, KL: 0.0031
Epoch [11/100], Total Loss: 1.5632, Recon: 1.5602, KL: 0.0030
Epoch [12/100], Total Loss: 1.5627, Recon: 1.5598, KL: 0.0029
Epoch [13/100], Total Loss: 1.5607, Recon: 1.5578, KL: 0.0030
Epoch [14/100], Total Loss: 1.5596, Recon: 1.5567, KL: 0.0029
Epoch [15/100], Total Loss: 1.5589, Recon: 1.5560, KL: 0.0028
Epoch [16/100], Total Loss: 1.5581, Recon: 1.5553, KL: 0.0028
Epoch [17/100], Total Loss: 1.5577, Recon: 1.5549, KL: 0.0028
Epoch [18/100], Total Loss: 1.5575, Recon: 1.5547, KL: 0.0028
Epoch [19/100], Total Loss: 1.5568, Recon: 1.5540, KL: 0.0028
Epoch [20/100], Total Loss: 1.5595, Recon: 1.5567, KL: 0.0028
Epoch [21/100], Total Loss: 1.5565, Recon: 1.5536, KL: 0.0028
Epoch [22/100], Total Loss: 1.5557, Recon: 1.5529, KL: 0.0028
Epoch [23/100], Total Loss: 1.5550, Recon: 1.5521, KL: 0.0029
Epoch [24/100], Total Loss: 1.5536, Recon: 1.5502, KL: 0.0034
Epoch [25/100], Total Loss: 1.5505, Recon: 1.5466, KL: 0.0040
Epoch [26/100], Total Loss: 1.5485, Recon: 1.5444, KL: 0.0040
Epoch [27/100], Total Loss: 1.5484, Recon: 1.5443, KL: 0.0041
Epoch [28/100], Total Loss: 1.5481, Recon: 1.5439, KL: 0.0042
Epoch [29/100], Total Loss: 1.5468, Recon: 1.5426, KL: 0.0042
Epoch [30/100], Total Loss: 1.5465, Recon: 1.5422, KL: 0.0042
Epoch [31/100], Total Loss: 1.5454, Recon: 1.5412, KL: 0.0042
Epoch [32/100], Total Loss: 1.5444, Recon: 1.5403, KL: 0.0041
Epoch [33/100], Total Loss: 1.5436, Recon: 1.5397, KL: 0.0039
Epoch [34/100], Total Loss: 1.5429, Recon: 1.5390, KL: 0.0038
Epoch [35/100], Total Loss: 1.5428, Recon: 1.5390, KL: 0.0038
Epoch [36/100], Total Loss: 1.5423, Recon: 1.5385, KL: 0.0038
Epoch [37/100], Total Loss: 1.5468, Recon: 1.5430, KL: 0.0038
Epoch [38/100], Total Loss: 1.5423, Recon: 1.5385, KL: 0.0038
Epoch [39/100], Total Loss: 1.5416, Recon: 1.5378, KL: 0.0038
Epoch [40/100], Total Loss: 1.5458, Recon: 1.5419, KL: 0.0039
Epoch [41/100], Total Loss: 1.5414, Recon: 1.5375, KL: 0.0039
Epoch [42/100], Total Loss: 1.5405, Recon: 1.5365, KL: 0.0039
Epoch [43/100], Total Loss: 1.5395, Recon: 1.5354, KL: 0.0041
Epoch [44/100], Total Loss: 1.5378, Recon: 1.5331, KL: 0.0047
Epoch [45/100], Total Loss: 1.5353, Recon: 1.5304, KL: 0.0049
Epoch [46/100], Total Loss: 1.5344, Recon: 1.5295, KL: 0.0049
Epoch [47/100], Total Loss: 1.5329, Recon: 1.5280, KL: 0.0050
Epoch [48/100], Total Loss: 1.5325, Recon: 1.5276, KL: 0.0049
Epoch [49/100], Total Loss: 1.5317, Recon: 1.5269, KL: 0.0048
Epoch [50/100], Total Loss: 1.5309, Recon: 1.5261, KL: 0.0048
Epoch [51/100], Total Loss: 1.5303, Recon: 1.5255, KL: 0.0048
Epoch [52/100], Total Loss: 1.5306, Recon: 1.5257, KL: 0.0049
Epoch [53/100], Total Loss: 1.5304, Recon: 1.5255, KL: 0.0049
Epoch [54/100], Total Loss: 1.5294, Recon: 1.5246, KL: 0.0049
Epoch [55/100], Total Loss: 1.5289, Recon: 1.5240, KL: 0.0049
Epoch [56/100], Total Loss: 1.5284, Recon: 1.5235, KL: 0.0049
Epoch [57/100], Total Loss: 1.5307, Recon: 1.5257, KL: 0.0050
Epoch [58/100], Total Loss: 1.5283, Recon: 1.5233, KL: 0.0050
Epoch [59/100], Total Loss: 1.5273, Recon: 1.5224, KL: 0.0049
Epoch [60/100], Total Loss: 1.5270, Recon: 1.5220, KL: 0.0050
Epoch [61/100], Total Loss: 1.5281, Recon: 1.5231, KL: 0.0050
Epoch [62/100], Total Loss: 1.5264, Recon: 1.5213, KL: 0.0050
Epoch [63/100], Total Loss: 1.5261, Recon: 1.5211, KL: 0.0050
Epoch [64/100], Total Loss: 1.5254, Recon: 1.5203, KL: 0.0050
Epoch [65/100], Total Loss: 1.5287, Recon: 1.5236, KL: 0.0050
Epoch [66/100], Total Loss: 1.5263, Recon: 1.5211, KL: 0.0051
Epoch [67/100], Total Loss: 1.5251, Recon: 1.5200, KL: 0.0051
Epoch [68/100], Total Loss: 1.5246, Recon: 1.5195, KL: 0.0051
Epoch [69/100], Total Loss: 1.5247, Recon: 1.5195, KL: 0.0052
Epoch [70/100], Total Loss: 1.5238, Recon: 1.5186, KL: 0.0051
Epoch [71/100], Total Loss: 1.5235, Recon: 1.5183, KL: 0.0051
Epoch [72/100], Total Loss: 1.5230, Recon: 1.5179, KL: 0.0052
Epoch [73/100], Total Loss: 1.5240, Recon: 1.5188, KL: 0.0052
Epoch [74/100], Total Loss: 1.5232, Recon: 1.5180, KL: 0.0052
Epoch [75/100], Total Loss: 1.5228, Recon: 1.5176, KL: 0.0052
Epoch [76/100], Total Loss: 1.5222, Recon: 1.5170, KL: 0.0052
Epoch [77/100], Total Loss: 1.5227, Recon: 1.5174, KL: 0.0053
Epoch [78/100], Total Loss: 1.5234, Recon: 1.5182, KL: 0.0052
Epoch [79/100], Total Loss: 1.5216, Recon: 1.5163, KL: 0.0053
Epoch [80/100], Total Loss: 1.5208, Recon: 1.5155, KL: 0.0053
Epoch [81/100], Total Loss: 1.5207, Recon: 1.5154, KL: 0.0052
Epoch [82/100], Total Loss: 1.5208, Recon: 1.5156, KL: 0.0053
Epoch [83/100], Total Loss: 1.5238, Recon: 1.5184, KL: 0.0053
Epoch [84/100], Total Loss: 1.5216, Recon: 1.5162, KL: 0.0054
Epoch [85/100], Total Loss: 1.5200, Recon: 1.5146, KL: 0.0053
Epoch [86/100], Total Loss: 1.5205, Recon: 1.5151, KL: 0.0054
Epoch [87/100], Total Loss: 1.5193, Recon: 1.5140, KL: 0.0053
Epoch [88/100], Total Loss: 1.5192, Recon: 1.5138, KL: 0.0054
Epoch [89/100], Total Loss: 1.5188, Recon: 1.5134, KL: 0.0054
Epoch [90/100], Total Loss: 1.5187, Recon: 1.5133, KL: 0.0054
Epoch [91/100], Total Loss: 1.5183, Recon: 1.5129, KL: 0.0054
Epoch [92/100], Total Loss: 1.5186, Recon: 1.5131, KL: 0.0054
Epoch [93/100], Total Loss: 1.5181, Recon: 1.5127, KL: 0.0054
Epoch [94/100], Total Loss: 1.5184, Recon: 1.5130, KL: 0.0054
Epoch [95/100], Total Loss: 1.5254, Recon: 1.5197, KL: 0.0057
Epoch [96/100], Total Loss: 1.5190, Recon: 1.5135, KL: 0.0055
Epoch [97/100], Total Loss: 1.5172, Recon: 1.5118, KL: 0.0055
Epoch [98/100], Total Loss: 1.5169, Recon: 1.5114, KL: 0.0055
Epoch [99/100], Total Loss: 1.5168, Recon: 1.5113, KL: 0.0055
Epoch [100/100], Total Loss: 1.5171, Recon: 1.5116, KL: 0.0055
Training loss plots saved to /workspace/AE/results/training/trial/
Training losses saved to /workspace/AE/results/training/trial/trial_ZINBVAE_20260114_164900_conv_training_losses.json

==================================================
EVALUATING ON TRAINING DATA
==================================================

==================================================
TEST RESULTS
==================================================
Test Loss (ZINB NLL): 1.514684
Mean Absolute Error (MAE): 2.211315
R² Score: -33.571625
Reconstruction Loss: 1.509304
KL Divergence: 0.005380
==================================================

Using raw counts for evaluation metrics.
29648000 13164927 16483073
ZINB metrics saved to /workspace/AE/results/training/trial/trial_ZINBVAE_20260114_164901_conv_test_metrics.json
ZINB-specific plots saved to /workspace/AE/results/training/trial/

==================================================
TEST RESULTS
==================================================
Test Loss (ZINB NLL): 1.656320
Mean Absolute Error (MAE): 2.375790
R² Score: -34.390751
Reconstruction Loss: 1.651205
KL Divergence: 0.005115
==================================================

Using raw counts for evaluation metrics.
3920000 1662825 2257175
ZINB metrics saved to /workspace/AE/results/testing/trial/trial_ZINBVAE_20260114_165211_conv_test_metrics.json
ZINB-specific plots saved to /workspace/AE/results/testing/trial/
