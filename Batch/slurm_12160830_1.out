Task 1: Training ZINBVAE
Device: cuda
Loading training data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_train_data.npy
Loading test data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_test_data.npy
Number of training samples: 14824
============================================================
TRAINING ZINB VARIATIONAL AUTOENCODER (ZINBVAE)
============================================================
Epoch [1/100], Total Loss: 1.6437, Recon: 1.6378, KL: 0.0059
Epoch [2/100], Total Loss: 1.6024, Recon: 1.6001, KL: 0.0023
Epoch [3/100], Total Loss: 1.5971, Recon: 1.5944, KL: 0.0027
Epoch [4/100], Total Loss: 1.5896, Recon: 1.5855, KL: 0.0041
Epoch [5/100], Total Loss: 1.5774, Recon: 1.5733, KL: 0.0041
Epoch [6/100], Total Loss: 1.5722, Recon: 1.5685, KL: 0.0037
Epoch [7/100], Total Loss: 1.5694, Recon: 1.5659, KL: 0.0035
Epoch [8/100], Total Loss: 1.5676, Recon: 1.5640, KL: 0.0036
Epoch [9/100], Total Loss: 1.5673, Recon: 1.5637, KL: 0.0036
Epoch [10/100], Total Loss: 1.5687, Recon: 1.5653, KL: 0.0034
Epoch [11/100], Total Loss: 1.5642, Recon: 1.5608, KL: 0.0034
Epoch [12/100], Total Loss: 1.5622, Recon: 1.5589, KL: 0.0033
Epoch [13/100], Total Loss: 1.5623, Recon: 1.5592, KL: 0.0031
Epoch [14/100], Total Loss: 1.5598, Recon: 1.5568, KL: 0.0030
Epoch [15/100], Total Loss: 1.5593, Recon: 1.5565, KL: 0.0029
Epoch [16/100], Total Loss: 1.5627, Recon: 1.5599, KL: 0.0028
Epoch [17/100], Total Loss: 1.5596, Recon: 1.5568, KL: 0.0028
Epoch [18/100], Total Loss: 1.5576, Recon: 1.5548, KL: 0.0028
Epoch [19/100], Total Loss: 1.5583, Recon: 1.5556, KL: 0.0027
Epoch [20/100], Total Loss: 1.5571, Recon: 1.5544, KL: 0.0027
Epoch [21/100], Total Loss: 1.5581, Recon: 1.5552, KL: 0.0029
Epoch [22/100], Total Loss: 1.5565, Recon: 1.5538, KL: 0.0027
Epoch [23/100], Total Loss: 1.5566, Recon: 1.5539, KL: 0.0027
Epoch [24/100], Total Loss: 1.5558, Recon: 1.5531, KL: 0.0027
Epoch [25/100], Total Loss: 1.5575, Recon: 1.5547, KL: 0.0028
Epoch [26/100], Total Loss: 1.5550, Recon: 1.5523, KL: 0.0027
Epoch [27/100], Total Loss: 1.5548, Recon: 1.5521, KL: 0.0027
Epoch [28/100], Total Loss: 1.5544, Recon: 1.5517, KL: 0.0027
Epoch [29/100], Total Loss: 1.5550, Recon: 1.5523, KL: 0.0027
Epoch [30/100], Total Loss: 1.5534, Recon: 1.5506, KL: 0.0028
Epoch [31/100], Total Loss: 1.5495, Recon: 1.5458, KL: 0.0037
Epoch [32/100], Total Loss: 1.5481, Recon: 1.5442, KL: 0.0039
Epoch [33/100], Total Loss: 1.5463, Recon: 1.5421, KL: 0.0042
Epoch [34/100], Total Loss: 1.5424, Recon: 1.5375, KL: 0.0049
Epoch [35/100], Total Loss: 1.5411, Recon: 1.5363, KL: 0.0049
Epoch [36/100], Total Loss: 1.5383, Recon: 1.5334, KL: 0.0049
Epoch [37/100], Total Loss: 1.5369, Recon: 1.5319, KL: 0.0050
Epoch [38/100], Total Loss: 1.5352, Recon: 1.5303, KL: 0.0049
Epoch [39/100], Total Loss: 1.5341, Recon: 1.5294, KL: 0.0047
Epoch [40/100], Total Loss: 1.5340, Recon: 1.5294, KL: 0.0046
Epoch [41/100], Total Loss: 1.5361, Recon: 1.5313, KL: 0.0048
Epoch [42/100], Total Loss: 1.5330, Recon: 1.5283, KL: 0.0047
Epoch [43/100], Total Loss: 1.5325, Recon: 1.5278, KL: 0.0047
Epoch [44/100], Total Loss: 1.5316, Recon: 1.5268, KL: 0.0048
Epoch [45/100], Total Loss: 1.5292, Recon: 1.5238, KL: 0.0054
Epoch [46/100], Total Loss: 1.5267, Recon: 1.5211, KL: 0.0057
Epoch [47/100], Total Loss: 1.5320, Recon: 1.5260, KL: 0.0059
Epoch [48/100], Total Loss: 1.5331, Recon: 1.5271, KL: 0.0060
Epoch [49/100], Total Loss: 1.5242, Recon: 1.5183, KL: 0.0059
Epoch [50/100], Total Loss: 1.5222, Recon: 1.5164, KL: 0.0058
Epoch [51/100], Total Loss: 1.5212, Recon: 1.5154, KL: 0.0058
Epoch [52/100], Total Loss: 1.5203, Recon: 1.5145, KL: 0.0058
Epoch [53/100], Total Loss: 1.5194, Recon: 1.5136, KL: 0.0058
Epoch [54/100], Total Loss: 1.5181, Recon: 1.5123, KL: 0.0059
Epoch [55/100], Total Loss: 1.5177, Recon: 1.5118, KL: 0.0059
Epoch [56/100], Total Loss: 1.5184, Recon: 1.5125, KL: 0.0059
Epoch [57/100], Total Loss: 1.5167, Recon: 1.5107, KL: 0.0060
Epoch [58/100], Total Loss: 1.5156, Recon: 1.5096, KL: 0.0060
Epoch [59/100], Total Loss: 1.5148, Recon: 1.5087, KL: 0.0061
Epoch [60/100], Total Loss: 1.5138, Recon: 1.5077, KL: 0.0061
Epoch [61/100], Total Loss: 1.5130, Recon: 1.5068, KL: 0.0061
Epoch [62/100], Total Loss: 1.5146, Recon: 1.5084, KL: 0.0062
Epoch [63/100], Total Loss: 1.5130, Recon: 1.5067, KL: 0.0063
Epoch [64/100], Total Loss: 1.5107, Recon: 1.5044, KL: 0.0063
Epoch [65/100], Total Loss: 1.5103, Recon: 1.5040, KL: 0.0063
Epoch [66/100], Total Loss: 1.5091, Recon: 1.5027, KL: 0.0064
Epoch [67/100], Total Loss: 1.5083, Recon: 1.5019, KL: 0.0064
Epoch [68/100], Total Loss: 1.5087, Recon: 1.5022, KL: 0.0065
Epoch [69/100], Total Loss: 1.5081, Recon: 1.5015, KL: 0.0066
Epoch [70/100], Total Loss: 1.5072, Recon: 1.5006, KL: 0.0066
Epoch [71/100], Total Loss: 1.5073, Recon: 1.5006, KL: 0.0066
Epoch [72/100], Total Loss: 1.5048, Recon: 1.4982, KL: 0.0066
Epoch [73/100], Total Loss: 1.5044, Recon: 1.4976, KL: 0.0067
Epoch [74/100], Total Loss: 1.5039, Recon: 1.4970, KL: 0.0068
Epoch [75/100], Total Loss: 1.5032, Recon: 1.4964, KL: 0.0069
Epoch [76/100], Total Loss: 1.5026, Recon: 1.4957, KL: 0.0069
Epoch [77/100], Total Loss: 1.5011, Recon: 1.4942, KL: 0.0070
Epoch [78/100], Total Loss: 1.5007, Recon: 1.4936, KL: 0.0071
Epoch [79/100], Total Loss: 1.5073, Recon: 1.5001, KL: 0.0073
Epoch [80/100], Total Loss: 1.4998, Recon: 1.4925, KL: 0.0073
Epoch [81/100], Total Loss: 1.4987, Recon: 1.4914, KL: 0.0073
Epoch [82/100], Total Loss: 1.4976, Recon: 1.4902, KL: 0.0074
Epoch [83/100], Total Loss: 1.4976, Recon: 1.4901, KL: 0.0075
Epoch [84/100], Total Loss: 1.4961, Recon: 1.4885, KL: 0.0076
Epoch [85/100], Total Loss: 1.4948, Recon: 1.4872, KL: 0.0076
Epoch [86/100], Total Loss: 1.4945, Recon: 1.4868, KL: 0.0077
Epoch [87/100], Total Loss: 1.4937, Recon: 1.4859, KL: 0.0078
Epoch [88/100], Total Loss: 1.4939, Recon: 1.4860, KL: 0.0079
Epoch [89/100], Total Loss: 1.4934, Recon: 1.4854, KL: 0.0080
Epoch [90/100], Total Loss: 1.4912, Recon: 1.4833, KL: 0.0079
Epoch [91/100], Total Loss: 1.4899, Recon: 1.4819, KL: 0.0079
Epoch [92/100], Total Loss: 1.4901, Recon: 1.4821, KL: 0.0080
Epoch [93/100], Total Loss: 1.4887, Recon: 1.4807, KL: 0.0080
Epoch [94/100], Total Loss: 1.4888, Recon: 1.4808, KL: 0.0080
Epoch [95/100], Total Loss: 1.4893, Recon: 1.4812, KL: 0.0081
Epoch [96/100], Total Loss: 1.4886, Recon: 1.4805, KL: 0.0081
Epoch [97/100], Total Loss: 1.4858, Recon: 1.4776, KL: 0.0081
Epoch [98/100], Total Loss: 1.4849, Recon: 1.4768, KL: 0.0081
Epoch [99/100], Total Loss: 1.4845, Recon: 1.4764, KL: 0.0081
Epoch [100/100], Total Loss: 1.4839, Recon: 1.4758, KL: 0.0081
Training loss plots saved to /workspace/AE/results/training/trial_new/
Training losses saved to /workspace/AE/results/training/trial_new/trial_new_ZINBVAE_20260116_102959_conv_training_losses.json

==================================================
EVALUATING ON TRAINING DATA
==================================================

==================================================
TEST RESULTS
==================================================
Test Loss (ZINB NLL): 1.480451
Mean Absolute Error (MAE): 2.278755
R² Score: -60.278091
Reconstruction Loss: 1.472504
KL Divergence: 0.007946
==================================================

Using raw counts for evaluation metrics.
29648000 13164927 16483073
ZINB metrics saved to /workspace/AE/results/training/trial_new/trial_new_ZINBVAE_20260116_103002_conv_test_metrics.json
ZINB-specific plots saved to /workspace/AE/results/training/trial_new/

==================================================
TEST RESULTS
==================================================
Test Loss (ZINB NLL): 1.679497
Mean Absolute Error (MAE): 2.430413
R² Score: -46.447460
Reconstruction Loss: 1.671919
KL Divergence: 0.007578
==================================================

Using raw counts for evaluation metrics.
3920000 1662825 2257175
ZINB metrics saved to /workspace/AE/results/testing/trial_new/trial_new_ZINBVAE_20260116_103954_conv_test_metrics.json
ZINB-specific plots saved to /workspace/AE/results/testing/trial_new/
