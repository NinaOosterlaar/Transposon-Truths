Task 1: Training ZINBVAE
Device: cuda
Loading training data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_train_data.npy
Loading test data from: Data/processed_data/BinSize10_MovingAvgFalse_ZINB_test_data.npy
Number of training samples: 14824
============================================================
TRAINING ZINB VARIATIONAL AUTOENCODER (ZINBVAE)
============================================================
Epoch [1/100], Total Loss: 2.0027, Recon: 1.9888, KL: 0.0139
Epoch [2/100], Total Loss: 1.8909, Recon: 1.8833, KL: 0.0076
Epoch [3/100], Total Loss: 1.8832, Recon: 1.8759, KL: 0.0073
Epoch [4/100], Total Loss: 1.8772, Recon: 1.8703, KL: 0.0069
Epoch [5/100], Total Loss: 1.8718, Recon: 1.8656, KL: 0.0062
Epoch [6/100], Total Loss: 1.8709, Recon: 1.8653, KL: 0.0056
Epoch [7/100], Total Loss: 1.8695, Recon: 1.8643, KL: 0.0051
Epoch [8/100], Total Loss: 1.8656, Recon: 1.8608, KL: 0.0048
Epoch [9/100], Total Loss: 1.8644, Recon: 1.8599, KL: 0.0045
Epoch [10/100], Total Loss: 1.8649, Recon: 1.8605, KL: 0.0044
Epoch [11/100], Total Loss: 1.8635, Recon: 1.8592, KL: 0.0043
Epoch [12/100], Total Loss: 1.8617, Recon: 1.8576, KL: 0.0041
Epoch [13/100], Total Loss: 1.8650, Recon: 1.8608, KL: 0.0042
Epoch [14/100], Total Loss: 1.8627, Recon: 1.8587, KL: 0.0040
Epoch [15/100], Total Loss: 1.8608, Recon: 1.8570, KL: 0.0039
Epoch [16/100], Total Loss: 1.8598, Recon: 1.8559, KL: 0.0038
Epoch [17/100], Total Loss: 1.8588, Recon: 1.8550, KL: 0.0038
Epoch [18/100], Total Loss: 1.8535, Recon: 1.8490, KL: 0.0046
Epoch [19/100], Total Loss: 1.8513, Recon: 1.8464, KL: 0.0048
Epoch [20/100], Total Loss: 1.8477, Recon: 1.8429, KL: 0.0048
Epoch [21/100], Total Loss: 1.8471, Recon: 1.8424, KL: 0.0047
Epoch [22/100], Total Loss: 1.8472, Recon: 1.8426, KL: 0.0046
Epoch [23/100], Total Loss: 1.8466, Recon: 1.8420, KL: 0.0046
Epoch [24/100], Total Loss: 1.8435, Recon: 1.8390, KL: 0.0044
Epoch [25/100], Total Loss: 1.8436, Recon: 1.8392, KL: 0.0043
Epoch [26/100], Total Loss: 1.8434, Recon: 1.8391, KL: 0.0043
Epoch [27/100], Total Loss: 1.8408, Recon: 1.8366, KL: 0.0042
Epoch [28/100], Total Loss: 1.8430, Recon: 1.8388, KL: 0.0042
Epoch [29/100], Total Loss: 1.8407, Recon: 1.8365, KL: 0.0042
Epoch [30/100], Total Loss: 1.8397, Recon: 1.8355, KL: 0.0042
Epoch [31/100], Total Loss: 1.8393, Recon: 1.8352, KL: 0.0041
Epoch [32/100], Total Loss: 1.8383, Recon: 1.8342, KL: 0.0041
Epoch [33/100], Total Loss: 1.8377, Recon: 1.8334, KL: 0.0043
Epoch [34/100], Total Loss: 1.8334, Recon: 1.8283, KL: 0.0052
Epoch [35/100], Total Loss: 1.8305, Recon: 1.8253, KL: 0.0052
Epoch [36/100], Total Loss: 1.8284, Recon: 1.8232, KL: 0.0052
Epoch [37/100], Total Loss: 1.8263, Recon: 1.8212, KL: 0.0051
Epoch [38/100], Total Loss: 1.8269, Recon: 1.8217, KL: 0.0052
Epoch [39/100], Total Loss: 1.8255, Recon: 1.8204, KL: 0.0051
Epoch [40/100], Total Loss: 1.8235, Recon: 1.8183, KL: 0.0051
Epoch [41/100], Total Loss: 1.8230, Recon: 1.8178, KL: 0.0052
Epoch [42/100], Total Loss: 1.8224, Recon: 1.8172, KL: 0.0052
Epoch [43/100], Total Loss: 1.8212, Recon: 1.8160, KL: 0.0053
Epoch [44/100], Total Loss: 1.8201, Recon: 1.8148, KL: 0.0053
Epoch [45/100], Total Loss: 1.8200, Recon: 1.8146, KL: 0.0053
Epoch [46/100], Total Loss: 1.8215, Recon: 1.8161, KL: 0.0054
Epoch [47/100], Total Loss: 1.8190, Recon: 1.8136, KL: 0.0054
Epoch [48/100], Total Loss: 1.8178, Recon: 1.8123, KL: 0.0054
Epoch [49/100], Total Loss: 1.8162, Recon: 1.8107, KL: 0.0055
Epoch [50/100], Total Loss: 1.8158, Recon: 1.8103, KL: 0.0055
Epoch [51/100], Total Loss: 1.8147, Recon: 1.8092, KL: 0.0055
Epoch [52/100], Total Loss: 1.8152, Recon: 1.8096, KL: 0.0056
Epoch [53/100], Total Loss: 1.8135, Recon: 1.8080, KL: 0.0056
Epoch [54/100], Total Loss: 1.8124, Recon: 1.8068, KL: 0.0056
Epoch [55/100], Total Loss: 1.8118, Recon: 1.8062, KL: 0.0056
Epoch [56/100], Total Loss: 1.8109, Recon: 1.8053, KL: 0.0057
Epoch [57/100], Total Loss: 1.8116, Recon: 1.8058, KL: 0.0057
Epoch [58/100], Total Loss: 1.8120, Recon: 1.8062, KL: 0.0058
Epoch [59/100], Total Loss: 1.8097, Recon: 1.8039, KL: 0.0058
Epoch [60/100], Total Loss: 1.8084, Recon: 1.8027, KL: 0.0058
Epoch [61/100], Total Loss: 1.8075, Recon: 1.8017, KL: 0.0058
Epoch [62/100], Total Loss: 1.8072, Recon: 1.8014, KL: 0.0058
Epoch [63/100], Total Loss: 1.8072, Recon: 1.8014, KL: 0.0059
Epoch [64/100], Total Loss: 1.8055, Recon: 1.7996, KL: 0.0059
Epoch [65/100], Total Loss: 1.8052, Recon: 1.7993, KL: 0.0059
Epoch [66/100], Total Loss: 1.8044, Recon: 1.7984, KL: 0.0060
Epoch [67/100], Total Loss: 1.8041, Recon: 1.7981, KL: 0.0060
Epoch [68/100], Total Loss: 1.8038, Recon: 1.7976, KL: 0.0061
Epoch [69/100], Total Loss: 1.8082, Recon: 1.8017, KL: 0.0065
Epoch [70/100], Total Loss: 1.8025, Recon: 1.7960, KL: 0.0065
Epoch [71/100], Total Loss: 1.8007, Recon: 1.7941, KL: 0.0066
Epoch [72/100], Total Loss: 1.8000, Recon: 1.7933, KL: 0.0067
Epoch [73/100], Total Loss: 1.7992, Recon: 1.7924, KL: 0.0068
Epoch [74/100], Total Loss: 1.7981, Recon: 1.7912, KL: 0.0069
Epoch [75/100], Total Loss: 1.7970, Recon: 1.7901, KL: 0.0070
Epoch [76/100], Total Loss: 1.7962, Recon: 1.7892, KL: 0.0070
Epoch [77/100], Total Loss: 1.7956, Recon: 1.7885, KL: 0.0071
Epoch [78/100], Total Loss: 1.7947, Recon: 1.7875, KL: 0.0072
Epoch [79/100], Total Loss: 1.7936, Recon: 1.7863, KL: 0.0073
Epoch [80/100], Total Loss: 1.7929, Recon: 1.7856, KL: 0.0072
Epoch [81/100], Total Loss: 1.7916, Recon: 1.7844, KL: 0.0072
Epoch [82/100], Total Loss: 1.7901, Recon: 1.7830, KL: 0.0072
Epoch [83/100], Total Loss: 1.7893, Recon: 1.7822, KL: 0.0071
Epoch [84/100], Total Loss: 1.7888, Recon: 1.7816, KL: 0.0071
Epoch [85/100], Total Loss: 1.7888, Recon: 1.7816, KL: 0.0072
Epoch [86/100], Total Loss: 1.7873, Recon: 1.7801, KL: 0.0072
Epoch [87/100], Total Loss: 1.7871, Recon: 1.7799, KL: 0.0072
Epoch [88/100], Total Loss: 1.7861, Recon: 1.7789, KL: 0.0072
Epoch [89/100], Total Loss: 1.7851, Recon: 1.7778, KL: 0.0072
Epoch [90/100], Total Loss: 1.7851, Recon: 1.7778, KL: 0.0073
Epoch [91/100], Total Loss: 1.7838, Recon: 1.7765, KL: 0.0073
Epoch [92/100], Total Loss: 1.7837, Recon: 1.7763, KL: 0.0073
Epoch [93/100], Total Loss: 1.7833, Recon: 1.7759, KL: 0.0074
Epoch [94/100], Total Loss: 1.7822, Recon: 1.7748, KL: 0.0074
Epoch [95/100], Total Loss: 1.7824, Recon: 1.7750, KL: 0.0074
Epoch [96/100], Total Loss: 1.7807, Recon: 1.7733, KL: 0.0074
Epoch [97/100], Total Loss: 1.7808, Recon: 1.7734, KL: 0.0074
Epoch [98/100], Total Loss: 1.7813, Recon: 1.7738, KL: 0.0075
Epoch [99/100], Total Loss: 1.7803, Recon: 1.7728, KL: 0.0075
Epoch [100/100], Total Loss: 1.7790, Recon: 1.7715, KL: 0.0075
Training loss plots saved to /workspace/AE/results/training/trial2/
Training losses saved to /workspace/AE/results/training/trial2/trial2_ZINBVAE_20260116_120658_conv_training_losses.json

==================================================
EVALUATING ON TRAINING DATA
==================================================

==================================================
TEST RESULTS
==================================================
Test Loss (ZINB NLL): 1.774153
Mean Absolute Error (MAE): 2.413779
R² Score: 0.206464
Reconstruction Loss: 1.766668
KL Divergence: 0.007485
==================================================

Using raw counts for evaluation metrics.
29648000 13164927 16483073
ZINB metrics saved to /workspace/AE/results/training/trial2/trial2_ZINBVAE_20260116_120700_conv_test_metrics.json
ZINB-specific plots saved to /workspace/AE/results/training/trial2/

==================================================
TEST RESULTS
==================================================
Test Loss (ZINB NLL): 1.961538
Mean Absolute Error (MAE): 2.873887
R² Score: 0.024006
Reconstruction Loss: 1.954429
KL Divergence: 0.007109
==================================================

Using raw counts for evaluation metrics.
3920000 1662825 2257175
ZINB metrics saved to /workspace/AE/results/testing/trial2/trial2_ZINBVAE_20260116_121035_conv_test_metrics.json
ZINB-specific plots saved to /workspace/AE/results/testing/trial2/
